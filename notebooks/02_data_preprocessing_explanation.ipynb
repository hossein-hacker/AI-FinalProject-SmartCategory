{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explaining the Data Preprocessing Pipeline\n",
    "\n",
    "This notebook explains the 3-step data preprocessing pipeline used to clean, merge, and balance the product category dataset. The goal is to transform the raw data into a format suitable for training a deep learning model for image-based product classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Problem: Many Imbalanced and Redundant Categories\n",
    "\n",
    "The original dataset has a large number of categories (248), many of which are semantically similar (e.g., \"Men's T-Shirts\" and \"Men's Tees\"). Furthermore, the number of products in each category is highly imbalanced. This poses a challenge for training a robust classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Solution: A 3-Step Pipeline\n",
    "\n",
    "To address this, we use a three-script pipeline:\n",
    "\n",
    "1.  `create_category_mappings.py`: Merges semantically similar categories using NLP and clustering.\n",
    "2.  `apply_category_mapping.py`: Applies this new mapping to the main products dataset.\n",
    "3.  `filter_by_product_count.py`: Filters out categories with too few products and re-indexes the final category IDs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Semantic Category Merging (`create_category_mappings.py`)\n",
    "\n",
    "**Goal:** To group similar categories based on their names.\n",
    "\n",
    "**How it works:**\n",
    "\n",
    "1.  **Load Categories:** It starts by loading the original `categories.csv` file.\n",
    "2.  **Generate Embeddings:** It uses the `sentence-transformers` library with the `all-MiniLM-L6-v2` model to convert each category name into a numerical vector (embedding). These embeddings capture the semantic meaning of the names.\n",
    "3.  **Cluster Embeddings:** It then uses `KMeans` clustering to group these embeddings into a smaller number of clusters (`NUM_CLUSTERS = 50`). Categories with similar meanings will have embeddings that are close to each other in the vector space and will be grouped into the same cluster.\n",
    "4.  **Create Mapping File:** The script creates a new file, `category_mapping.csv`, which contains the original `category_id` and a new `merged_category_id` (the cluster ID)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "# The original file with all 248 categories\n",
    "CATEGORIES_FILE_PATH = \"data/raw/categories.csv\"\n",
    "# The desired number of final, merged categories\n",
    "NUM_CLUSTERS = 50\n",
    "# The output file that will store the mapping from old to new categories\n",
    "OUTPUT_MAPPING_FILE = \"data/processed/category_mapping.csv\"\n",
    "\n",
    "# Load the original categories data\n",
    "categories_df = pd.read_csv(CATEGORIES_FILE_PATH)\n",
    "categories_df.rename(columns={'id': 'category_id'}, inplace=True)\n",
    "\n",
    "# Generate sentence embeddings for category names\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "category_embeddings = model.encode(categories_df['category_name'].tolist())\n",
    "\n",
    "# Cluster the embeddings\n",
    "kmeans = KMeans(n_clusters=NUM_CLUSTERS, random_state=42, n_init='auto')\n",
    "cluster_labels = kmeans.fit_predict(category_embeddings)\n",
    "categories_df['merged_category_id'] = cluster_labels\n",
    "\n",
    "# Save the mapping\n",
    "output_df = categories_df[['category_id', 'category_name', 'merged_category_id']]\n",
    "output_df.to_csv(OUTPUT_MAPPING_FILE, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Applying the Mapping (`apply_category_mapping.py`)\n",
    "\n",
    "**Goal:** To apply the newly created category mapping to the entire product dataset.\n",
    "\n",
    "**How it works:**\n",
    "\n",
    "1.  **Load Datasets:** It loads both the large, original `products.csv` and the `category_mapping.csv` created in the previous step.\n",
    "2.  **Map IDs:** It efficiently maps the `category_id` in the products DataFrame to the `merged_category_id` from the mapping file.\n",
    "3.  **Save Cleaned File:** It saves a new file, `products_cleaned.csv`, containing the product information with the new `merged_category_id`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ORIGINAL_PRODUCTS_FILE = \"data/raw/products.csv\"\n",
    "CATEGORY_MAPPING_FILE = \"data/processed/category_mapping.csv\"\n",
    "OUTPUT_PRODUCTS_FILE = \"data/processed/products_cleaned.csv\"\n",
    "\n",
    "# Load the datasets\n",
    "products_df = pd.read_csv(ORIGINAL_PRODUCTS_FILE)\n",
    "mapping_df = pd.read_csv(CATEGORY_MAPPING_FILE)\n",
    "\n",
    "# Create a mapping dictionary for efficiency\n",
    "id_to_merged_id = pd.Series(mapping_df.merged_category_id.values, index=mapping_df.category_id).to_dict()\n",
    "\n",
    "# Apply the mapping\n",
    "products_df['merged_category_id'] = products_df['category_id'].map(id_to_merged_id)\n",
    "\n",
    "# Save the result\n",
    "final_df = products_df[['asin', 'title', 'imgUrl', 'merged_category_id']]\n",
    "final_df.to_csv(OUTPUT_PRODUCTS_FILE, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Filtering by Product Count (`filter_by_product_count.py`)\n",
    "\n",
    "**Goal:** To ensure each category has enough products for effective model training and to create final, sequential category IDs.\n",
    "\n",
    "**How it works:**\n",
    "\n",
    "1.  **Count Products:** It loads the `products_cleaned.csv` and counts the number of products in each `merged_category_id`. \n",
    "2.  **Filter Categories:** It identifies and keeps only the categories that have more than a `MIN_PRODUCT_COUNT` (e.g., 5000) of products.\n",
    "3.  **Re-index Category IDs:** This is a crucial step. After filtering, the remaining `merged_category_id`s might have gaps (e.g., 0, 2, 5, 8). Most machine learning frameworks, including PyTorch, expect class labels to be sequential (0, 1, 2, 3...). This script re-indexes the filtered category IDs to be continuous.\n",
    "4.  **Overwrite Files:** Finally, it overwrites both `products_cleaned.csv` and `category_mapping.csv` with the filtered and re-indexed data. This results in the final, analysis-ready dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "MIN_PRODUCT_COUNT = 5000\n",
    "PRODUCTS_FILE = \"data/processed/products_cleaned.csv\"\n",
    "MAPPING_FILE = \"data/processed/category_mapping.csv\"\n",
    "\n",
    "# Load data\n",
    "products_df = pd.read_csv(PRODUCTS_FILE)\n",
    "mapping_df = pd.read_csv(MAPPING_FILE)\n",
    "\n",
    "# Calculate product counts and identify valid categories\n",
    "category_counts = products_df['merged_category_id'].value_counts()\n",
    "valid_category_ids = category_counts[category_counts >= MIN_PRODUCT_COUNT].index.tolist()\n",
    "\n",
    "# Filter dataframes\n",
    "products_df = products_df[products_df['merged_category_id'].isin(valid_category_ids)]\n",
    "mapping_df = mapping_df[mapping_df['merged_category_id'].isin(valid_category_ids)]\n",
    "\n",
    "# Re-index the final category IDs to be sequential\n",
    "unique_ids = products_df['merged_category_id'].unique()\n",
    "old_to_new_id_map = {old_id: new_id for new_id, old_id in enumerate(unique_ids)}\n",
    "products_df['final_category_id'] = products_df['merged_category_id'].map(old_to_new_id_map)\n",
    "\n",
    "# Clean up and rename columns\n",
    "products_df = products_df.drop(columns=['merged_category_id'])\n",
    "products_df.rename(columns={'final_category_id': 'category_id'}, inplace=True)\n",
    "\n",
    "# Overwrite the files with the final data\n",
    "products_df.to_csv(PRODUCTS_FILE, index=False)\n",
    "mapping_df.to_csv(MAPPING_FILE, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This pipeline effectively transforms a large, messy, and imbalanced dataset into a clean, well-structured, and balanced one. The final `products_cleaned.csv` and `category_mapping.csv` files are ready to be used for training a deep learning model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
