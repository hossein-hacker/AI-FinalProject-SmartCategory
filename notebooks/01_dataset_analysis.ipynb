{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07b0a71b",
   "metadata": {},
   "source": [
    "# Dataset Analysis and Pipeline Validation\n",
    "## Image-Based Product Category Classification\n",
    "\n",
    "This notebook covers the initial analysis of the raw dataset and validates the effectiveness of our automated data preparation pipeline.\n",
    "\n",
    "The goals of this notebook are to:\n",
    "- Inspect the raw dataset and its original category distribution.\n",
    "- **Validate the new category structure** created by our NLP-based merging script.\n",
    "- **Analyze the balance of the final, merged dataset**.\n",
    "- Verify data quality, such as the validity of image URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e59018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tools needed for data analysis and visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "plt.style.use(\"default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec0c95e",
   "metadata": {},
   "source": [
    "## 1. Loading the Dataset\n",
    "\n",
    "The dataset is provided as two CSV files, the first one contains product title, image URLs and category id.\n",
    "The categories.csv, has the categories names.\n",
    "Due to its size, the dataset is hosted externally and downloaded using a dedicated script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dba9bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_df = pd.read_csv(\"../data/raw/products.csv\")\n",
    "categories_df = pd.read_csv(\"../data/raw/categories.csv\")\n",
    "products_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5ba602",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of samples: {len(products_df)}\")\n",
    "print(f\"Number of columns: {len(products_df.columns)}\")\n",
    "products_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad505b8",
   "metadata": {},
   "source": [
    "- The dataset contains product title, image URLs and their corresponding category id.\n",
    "- The category labels are stored in a seperate csv file.\n",
    "- The following analysis focuses on cleaning and refining these fields."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109e2765",
   "metadata": {},
   "source": [
    "## 2. Raw Category Inspection\n",
    "\n",
    "We first examine the distribution of all available categories to understand their frequency and suitability for image-based classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54161df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_category_counts = products_df[\"category_id\"].value_counts()\n",
    "print(categories_df[[\"id\",\"category_name\"]].head())\n",
    "\n",
    "print(\"\\nMin frequency of a category: \" + str(raw_category_counts.min()))\n",
    "print(\"Max frequency of a category: \" + str(raw_category_counts.max()))\n",
    "print(\"Mean frequency of a category: \" + str(int(raw_category_counts.mean())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284af7c8",
   "metadata": {},
   "source": [
    "## 3. Automated Category Merging\n",
    "\n",
    "The original dataset contains 248 categories, many of which are either too specific, too broad, or semantically very similar. A manual approach to filtering or merging is not scalable or reproducible.\n",
    "\n",
    "Also there are some categories that have a few products in them, and can unbalance the dataset.\n",
    "\n",
    "To solve this, we implemented an automated pipeline that uses **NLP (Sentence-Transformers) and Clustering (K-Means)** to group the 248 original categories into a more manageable and balanced set of around 50 new categories. \n",
    "\n",
    "The following steps analyze the result of that pipeline.\n",
    "\n",
    "First, we load the final processed dataset and the mapping file generated by our scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9877b241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the results of the new data preparation pipeline\n",
    "products_cleaned_df = pd.read_csv(\"../data/processed/products_cleaned.csv\")\n",
    "mapping_df = pd.read_csv(\"../data/processed/category_mapping.csv\")\n",
    "\n",
    "print(f\"Loaded {len(products_cleaned_df)} cleaned products.\")\n",
    "print(f\"Loaded mapping for {len(mapping_df)} original categories into {mapping_df['merged_category_id'].nunique()} new categories.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863dd9ed",
   "metadata": {},
   "source": [
    "For securing the dataset, categories with fewer than 100 samples were removed to ensure\n",
    "a more balanced and learnable dataset.\n",
    "\n",
    "After modifying, the final category set is obtained.\n",
    "These categories are visually distinguishable and suitable for classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0ac18b",
   "metadata": {},
   "source": [
    "## 4. Dataset Balance Analysis\n",
    "\n",
    "We analyze the number of samples per category to assess dataset balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13752895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting ready for visualization\n",
    "category_counts = products_cleaned_df[\"merged_category_id\"].value_counts()\n",
    "category_counts_df = (\n",
    "    category_counts\n",
    "    .reset_index()\n",
    ")\n",
    "category_counts_df.columns = [\"merged_category_id\", \"count\"]\n",
    "category_counts_df = category_counts_df.merge(\n",
    "    mapping_df,\n",
    "    on=\"merged_category_id\",\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a12a68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "plt.bar(\n",
    "    category_counts_df[\"category_name\"],\n",
    "    category_counts_df[\"count\"]\n",
    ")\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel(\"Category\")\n",
    "plt.ylabel(\"Number of Products\")\n",
    "plt.title(\"Category Distribution\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f7aba3",
   "metadata": {},
   "source": [
    "The graph shows some amount imbalance across categories.\n",
    "This imbalance will be addressed in later phases using data augmentation and training strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a110d590",
   "metadata": {},
   "source": [
    "## 5. Image URL Quality Check\n",
    "\n",
    "To assess data quality, we verify whether image URLs are reachable.\n",
    "Due to dataset size, this check is performed on a random subset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cc84a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_url_valid(url):\n",
    "    try:\n",
    "        r = requests.get(\n",
    "            url,\n",
    "            timeout=5,\n",
    "            stream=True,\n",
    "            allow_redirects=True,\n",
    "            headers={\"User-Agent\": \"Mozilla/5.0\"}\n",
    "        )\n",
    "        return r.status_code == 200\n",
    "    except requests.RequestException:\n",
    "        return False\n",
    "    \n",
    "def check_urls_parallel(urls, max_workers=40):\n",
    "    results = []\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        for res in tqdm(executor.map(is_url_valid, urls), total=len(urls)):\n",
    "            results.append(res)\n",
    "    return results\n",
    "\n",
    "sample_df = products_cleaned_df.sample(200, random_state=42).copy()\n",
    "\n",
    "sample_df[\"valid\"] = check_urls_parallel(\n",
    "    sample_df[\"imgUrl\"].tolist(),\n",
    "    max_workers=20\n",
    ")\n",
    "\n",
    "sample_df[\"valid\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c657f030",
   "metadata": {},
   "source": [
    "The sample-based validation indicates that most image URLs are reachable.\n",
    "Invalid URLs are removed automatically during the image download and training stage, where missing images will be skipped."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74222791",
   "metadata": {},
   "source": [
    "## 6. Example Images from Each Category\n",
    "\n",
    "To better understand the visual characteristics of each category and verify that\n",
    "categories are visually distinguishable, we display a small number of example\n",
    "images from each category.\n",
    "\n",
    "For each category, 2â€“3 sample images are randomly selected and visualized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35586f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import time\n",
    "\n",
    "def load_image_from_url(url, timeout=5, retries=3, backoff=1.0):\n",
    "    \"\"\"\n",
    "    Fetch an image from a URL and return a PIL Image.\n",
    "\n",
    "    Args:\n",
    "        url (str): Image URL\n",
    "        timeout (int): Request timeout in seconds\n",
    "        retries (int): Number of retry attempts\n",
    "        backoff (float): Seconds to wait between retries\n",
    "\n",
    "    Returns:\n",
    "        PIL.Image or None\n",
    "    \"\"\"\n",
    "    for attempt in range(1, retries + 1):\n",
    "        try:\n",
    "            response = requests.get(url, timeout=timeout)\n",
    "            response.raise_for_status()\n",
    "            return Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "\n",
    "        except Exception as e:\n",
    "            if attempt < retries:\n",
    "                time.sleep(backoff)\n",
    "            else:\n",
    "                return None\n",
    "    \n",
    "def fetch_image(row):\n",
    "    \"\"\"\n",
    "    Fetch image for a single dataframe row.\n",
    "    Returns (category, image or None).\n",
    "    \"\"\"\n",
    "    img = load_image_from_url(row[\"imgUrl\"])\n",
    "    return row[\"merged_category_id\"], img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63f13da",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_per_category = 2\n",
    "rows = []\n",
    "categories = products_cleaned_df[\"merged_category_id\"].unique()\n",
    "n_rows = len(categories)\n",
    "n_cols = images_per_category\n",
    "\n",
    "for category in categories:\n",
    "    category_df = products_cleaned_df[\n",
    "        products_cleaned_df[\"merged_category_id\"] == category\n",
    "    ]\n",
    "    sampled = category_df.sample(\n",
    "        min(images_per_category, len(category_df)),\n",
    "        random_state=42\n",
    "    )\n",
    "    rows.extend(sampled.to_dict(\"records\"))\n",
    "\n",
    "images = []\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=20) as executor:\n",
    "    for result in tqdm(\n",
    "        executor.map(fetch_image, rows),\n",
    "        total=len(rows),\n",
    "        desc=\"Downloading images\"\n",
    "    ):\n",
    "        images.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837b200f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "    n_rows,\n",
    "    n_cols,\n",
    "    figsize=(n_cols * 2, n_rows * 2)\n",
    ")\n",
    "\n",
    "idx = 0\n",
    "for row_idx, category in enumerate(categories):\n",
    "    for col_idx in range(images_per_category):\n",
    "        ax = axes[row_idx][col_idx]\n",
    "        img_category, img = images[idx]\n",
    "\n",
    "        if img is not None:\n",
    "            ax.imshow(img)\n",
    "        else:\n",
    "            ax.text(0.5, 0.5, \"Image\\nNot Available\",\n",
    "                    ha=\"center\", va=\"center\")\n",
    "\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "        if col_idx == 0:\n",
    "            ax.set_ylabel(str(category), rotation=0, labelpad=40)\n",
    "\n",
    "        idx += 1\n",
    "# plt.title(\"Example Images from Each Category\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92642914",
   "metadata": {},
   "source": [
    "The example images demonstrate that the selected categories are visually distinct\n",
    "and suitable for image-based classification. This qualitative inspection supports\n",
    "the feasibility of the proposed learning task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3827c0a2",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we performed a full cycle of data analysis and pipeline validation:\n",
    "- We began by inspecting the **raw dataset** and its original, imbalanced category structure.\n",
    "- We then loaded the results of our **automated NLP-based category merging pipeline**.\n",
    "- We **visualized the final dataset's balance**, confirming that the new 50 categories are much more evenly distributed.\n",
    "- We reviewed the mapping to understand how original categories were grouped.\n",
    "- We verified the quality of image URLs in the dataset.\n",
    "\n",
    "The resulting dataset, `products_cleaned.csv`, is now validated and ready to serve as the foundation for model training."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
