{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07b0a71b",
   "metadata": {},
   "source": [
    "# Dataset Analysis and Pipeline Validation\n",
    "## Image-Based Product Category Classification\n",
    "\n",
    "This notebook covers the initial analysis of the raw dataset and validates the effectiveness of our automated data preparation pipeline.\n",
    "\n",
    "The goals of this notebook are to:\n",
    "- Inspect the raw dataset and its original category distribution.\n",
    "- **Validate the new category structure** created by our NLP-based merging script.\n",
    "- **Analyze the balance of the final, merged dataset**.\n",
    "- Verify data quality, such as the validity of image URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e59018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tools needed for data analysis and visualization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "plt.style.use(\"default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec0c95e",
   "metadata": {},
   "source": [
    "## 1. Loading the Dataset\n",
    "\n",
    "The dataset is provided as two CSV files, the first one contains product title, image URLs and category id.\n",
    "The categories.csv, has the categories names.\n",
    "Due to its size, the dataset is hosted externally and downloaded using a dedicated script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dba9bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "products_df = pd.read_csv(\"../data/raw/products.csv\")\n",
    "categories_df = pd.read_csv(\"../data/raw/categories.csv\")\n",
    "products_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5ba602",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of samples: {len(products_df)}\")\n",
    "print(f\"Number of columns: {len(products_df.columns)}\")\n",
    "products_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad505b8",
   "metadata": {},
   "source": [
    "- The dataset contains product title, image URLs and their corresponding category id.\n",
    "- The category labels are stored in a seperate csv file.\n",
    "- The following analysis focuses on cleaning and refining these fields."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109e2765",
   "metadata": {},
   "source": [
    "## 2. Raw Category Inspection\n",
    "\n",
    "We first examine the distribution of all available categories to understand their frequency and suitability for image-based classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54161df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_category_counts = products_df[\"category_id\"].value_counts()\n",
    "print(categories_df[[\"id\",\"category_name\"]].head())\n",
    "\n",
    "print(\"\\nMin frequency of a category: \" + str(raw_category_counts.min()))\n",
    "print(\"Max frequency of a category: \" + str(raw_category_counts.max()))\n",
    "print(\"Mean frequency of a category: \" + str(int(raw_category_counts.mean())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284af7c8",
   "metadata": {},
   "source": [
    "## 3. Automated Category Merging\n",
    "\n",
    "The original dataset contains 248 categories, many of which are either too specific, too broad, or semantically very similar. A manual approach to filtering or merging is not scalable or reproducible.\n",
    "\n",
    "Also there are some categories that have a few products in them, and can unbalance the dataset.\n",
    "\n",
    "To solve this, we implemented an automated pipeline that uses **NLP (Sentence-Transformers) and Clustering (K-Means)** to group the 248 original categories into a more manageable and balanced set of around 50 new categories. \n",
    "\n",
    "The following steps analyze the result of that pipeline.\n",
    "\n",
    "First, we load the final processed dataset and the mapping file generated by our scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9877b241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the results of the new data preparation pipeline\n",
    "products_cleaned_df = pd.read_csv(\"../data/processed/products_cleaned.csv\")\n",
    "mapping_df = pd.read_csv(\"../data/processed/category_mapping.csv\")\n",
    "\n",
    "print(f\"Loaded {len(products_cleaned_df)} cleaned products.\")\n",
    "print(f\"Loaded mapping for {len(mapping_df)} original categories into {mapping_df['merged_category_id'].nunique()} new categories.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863dd9ed",
   "metadata": {},
   "source": [
    "For securing the dataset, categories with fewer than 100 samples were removed to ensure\n",
    "a more balanced and learnable dataset.\n",
    "\n",
    "After modifying, the final category set is obtained.\n",
    "These categories are visually distinguishable and suitable for classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0ac18b",
   "metadata": {},
   "source": [
    "## 4. Dataset Balance Analysis\n",
    "\n",
    "We analyze the number of samples per category to assess dataset balance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13752895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting ready for visualization\n",
    "category_counts = products_cleaned_df[\"merged_category_id\"].value_counts()\n",
    "category_counts_df = (\n",
    "    category_counts\n",
    "    .reset_index()\n",
    ")\n",
    "category_counts_df.columns = [\"merged_category_id\", \"count\"]\n",
    "category_counts_df = category_counts_df.merge(\n",
    "    mapping_df,\n",
    "    on=\"merged_category_id\",\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a12a68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "plt.bar(\n",
    "    category_counts_df[\"category_name\"],\n",
    "    category_counts_df[\"count\"]\n",
    ")\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel(\"Category\")\n",
    "plt.ylabel(\"Number of Products\")\n",
    "plt.title(\"Category Distribution\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f7aba3",
   "metadata": {},
   "source": [
    "The graph shows some amount imbalance across categories.\n",
    "This imbalance will be addressed in later phases using data augmentation and training strategies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a110d590",
   "metadata": {},
   "source": [
    "## 5. Image URL Quality Check\n",
    "\n",
    "To assess data quality, we verify whether image URLs are reachable.\n",
    "Due to dataset size, this check is performed on a random subset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cc84a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_url_valid(url):\n",
    "    try:\n",
    "        r = requests.get(\n",
    "            url,\n",
    "            timeout=5,\n",
    "            stream=True,\n",
    "            allow_redirects=True,\n",
    "            headers={\"User-Agent\": \"Mozilla/5.0\"}\n",
    "        )\n",
    "        return r.status_code == 200\n",
    "    except requests.RequestException:\n",
    "        return False\n",
    "    \n",
    "def check_urls_parallel(urls, max_workers=40):\n",
    "    results = []\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        for res in tqdm(executor.map(is_url_valid, urls), total=len(urls)):\n",
    "            results.append(res)\n",
    "    return results\n",
    "\n",
    "sample_df = products_cleaned_df.sample(200, random_state=42).copy()\n",
    "\n",
    "sample_df[\"valid\"] = check_urls_parallel(\n",
    "    sample_df[\"imgUrl\"].tolist(),\n",
    "    max_workers=20\n",
    ")\n",
    "\n",
    "sample_df[\"valid\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c657f030",
   "metadata": {},
   "source": [
    "The sample-based validation indicates that most image URLs are reachable.\n",
    "Invalid URLs are removed automatically during the image download and training stage, where missing images will be skipped."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74222791",
   "metadata": {},
   "source": [
    "## 6. Example Images from Each Category\n",
    "\n",
    "To better understand the visual characteristics of each category and verify that\n",
    "categories are visually distinguishable, we display a small number of example\n",
    "images from each category.\n",
    "\n",
    "For each category, 2–3 sample images are randomly selected and visualized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ca8e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import hashlib\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "# Base cache directory\n",
    "IMAGE_CACHE_DIR = \"../data/raw/images\"\n",
    "os.makedirs(IMAGE_CACHE_DIR, exist_ok=True)\n",
    "\n",
    "def _url_to_filename(url):\n",
    "    \"\"\"\n",
    "    Create a deterministic filename from a URL using hashing.\n",
    "    \"\"\"\n",
    "    return hashlib.md5(url.encode(\"utf-8\")).hexdigest() + \".jpg\"\n",
    "\n",
    "\n",
    "def load_image_from_url(\n",
    "    url,\n",
    "    timeout=5,\n",
    "    retries=3,\n",
    "    backoff=1.0,\n",
    "    cache_dir=IMAGE_CACHE_DIR\n",
    "):\n",
    "    \"\"\"\n",
    "    Fetch an image from a URL with caching and retries.\n",
    "\n",
    "    If the image was previously downloaded, it is loaded from disk\n",
    "    instead of downloading again.\n",
    "\n",
    "    Args:\n",
    "        url (str): Image URL\n",
    "        timeout (int): Request timeout in seconds\n",
    "        retries (int): Number of retry attempts\n",
    "        backoff (float): Seconds to wait between retries\n",
    "        cache_dir (str): Directory for cached images\n",
    "\n",
    "    Returns:\n",
    "        PIL.Image or None\n",
    "    \"\"\"\n",
    "    filename = _url_to_filename(url)\n",
    "    filepath = os.path.join(cache_dir, filename)\n",
    "\n",
    "    # 1 -> Load from cache if exists\n",
    "    if os.path.exists(filepath):\n",
    "        try:\n",
    "            return Image.open(filepath).convert(\"RGB\")\n",
    "        except Exception:\n",
    "            # Corrupted cache → remove and re-download\n",
    "            os.remove(filepath)\n",
    "\n",
    "    # 2 -> Download with retries\n",
    "    for attempt in range(1, retries + 1):\n",
    "        try:\n",
    "            response = requests.get(url, timeout=timeout)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            # Ensure it's an image\n",
    "            if \"image\" not in response.headers.get(\"Content-Type\", \"\"):\n",
    "                raise ValueError(\"URL did not return an image\")\n",
    "\n",
    "            img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "\n",
    "            # Save to cache\n",
    "            img.save(filepath, format=\"JPEG\", quality=90)\n",
    "\n",
    "            return img\n",
    "\n",
    "        except Exception:\n",
    "            if attempt < retries:\n",
    "                time.sleep(backoff)\n",
    "            else:\n",
    "                return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35586f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_image_with_info(row):\n",
    "    \"\"\"\n",
    "    Fetch image and return metadata (Category ID, Image Object, Product Title).\n",
    "    \"\"\"\n",
    "    img = load_image_from_url(row[\"imgUrl\"])\n",
    "    # Return a tuple: (category_id, image_obj, product_title)\n",
    "    return row[\"merged_category_id\"], img, row[\"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63f13da",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_name = dict(zip(mapping_df[\"merged_category_id\"], mapping_df[\"category_name\"]))\n",
    "# Gather Data\n",
    "IMAGES_PER_CATEGORY = 2\n",
    "rows = []\n",
    "categories = products_cleaned_df[\"merged_category_id\"].unique()\n",
    "\n",
    "for category in categories:\n",
    "    cat_df = products_cleaned_df[products_cleaned_df[\"merged_category_id\"] == category]\n",
    "    # Sample data\n",
    "    sampled = cat_df.sample(min(IMAGES_PER_CATEGORY, len(cat_df)), random_state=42)\n",
    "    rows.extend(sampled.to_dict(\"records\"))\n",
    "\n",
    "# Download in Parallel\n",
    "images_with_meta = []\n",
    "with ThreadPoolExecutor(max_workers=20) as executor:\n",
    "    for result in tqdm(executor.map(fetch_image_with_info, rows), total=len(rows), desc=\"Downloading\"):\n",
    "        images_with_meta.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837b200f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "\n",
    "# Create Subplots\n",
    "n_rows = len(categories)\n",
    "n_cols = IMAGES_PER_CATEGORY\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    n_rows, \n",
    "    n_cols, \n",
    "    figsize=(n_cols * 4, n_rows * 3) # increased width slightly for text\n",
    ")\n",
    "\n",
    "idx = 0\n",
    "for row_idx, category_id in enumerate(categories):\n",
    "    for col_idx in range(IMAGES_PER_CATEGORY):\n",
    "        \n",
    "        if n_rows == 1:\n",
    "            ax = axes[col_idx]\n",
    "        else:\n",
    "            ax = axes[row_idx][col_idx]\n",
    "            \n",
    "        img_cat_id, img, title = images_with_meta[idx]\n",
    "\n",
    "        if img is not None:\n",
    "            ax.imshow(img)\n",
    "        else:\n",
    "            ax.text(0.5, 0.5, \"Image\\nNot Available\", \n",
    "                    ha=\"center\", va=\"center\")\n",
    "        \n",
    "        ax.axis(\"off\")\n",
    "\n",
    "        # Add Product Title to Image\n",
    "        wrapped_title = \"\\n\".join(textwrap.wrap(title, width=30))[:100] # Limit chars\n",
    "        ax.set_title(wrapped_title, fontsize=9)\n",
    "\n",
    "        # Add Category Name to Row \n",
    "        if col_idx == 0:\n",
    "            cat_name = id_to_name.get(category_id, f\"Cat: {category_id}\")\n",
    "            \n",
    "            wrapped_cat_name = \"\\n\".join(textwrap.wrap(cat_name, width=15))\n",
    "            \n",
    "            ax.set_ylabel(\n",
    "                wrapped_cat_name, \n",
    "                rotation=0, \n",
    "                labelpad=60,\n",
    "                fontsize=11, \n",
    "                fontweight='bold',\n",
    "                ha='right',\n",
    "                va='center'\n",
    "            )\n",
    "\n",
    "        idx += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92642914",
   "metadata": {},
   "source": [
    "The example images demonstrate that the selected categories are visually distinct\n",
    "and suitable for image-based classification. This qualitative inspection supports\n",
    "the feasibility of the proposed learning task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0308171d",
   "metadata": {},
   "source": [
    "## 7. Image Dimension Distribution\n",
    "\n",
    "Images collected from online marketplaces often vary significantly in resolution.\n",
    "To analyze this variability and justify image resizing during preprocessing,\n",
    "we examine the distribution of image widths and heights.\n",
    "\n",
    "A random sample of 1000 images is used for this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8d81f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample images\n",
    "SAMPLE_SIZE = 1000\n",
    "sample_df = products_cleaned_df.sample(\n",
    "    min(SAMPLE_SIZE, len(products_cleaned_df)),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "def get_image_size(url):\n",
    "    img = load_image_from_url(url)\n",
    "    if img is not None:\n",
    "        return img.size  # (width, height)\n",
    "    return None\n",
    "\n",
    "sizes = []\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=20) as executor:\n",
    "    for size in tqdm(\n",
    "        executor.map(get_image_size, sample_df[\"imgUrl\"]),\n",
    "        total=len(sample_df),\n",
    "        desc=\"Fetching image dimensions\"\n",
    "    ):\n",
    "        if size is not None:\n",
    "            sizes.append(size)\n",
    "\n",
    "print(f\"Collected dimensions for {len(sizes)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b446c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "widths, heights = zip(*sizes)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(widths, heights, alpha=0.4, s=10)\n",
    "plt.xlabel(\"Image Width (pixels)\")\n",
    "plt.ylabel(\"Image Height (pixels)\")\n",
    "plt.title(\"Image Width vs Height Distribution\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4154a19",
   "metadata": {},
   "source": [
    "The scatter plot shows a wide variation in image dimensions across the dataset.\n",
    "Both width and height span a large range of values, indicating that images are\n",
    "not captured or stored at a consistent resolution.\n",
    "\n",
    "This variability motivates the use of image resizing as a necessary\n",
    "preprocessing step before model training to ensure consistent input dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c33aa7e",
   "metadata": {},
   "source": [
    "### 8. Average Image Color per Category\n",
    "To get a high-level visual sense of the image data, we can compute the average color for images within each category. This can reveal dominating color biases in the dataset (e.g., electronics being mostly black or silver) and helps justify the use of color-based data augmentation. We'll sample 20 images from each category to compute a representative average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542bf802",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_color(url):\n",
    "    \"\"\"Fetches an image and computes its average RGB color.\"\"\"\n",
    "    try:\n",
    "        img = load_image_from_url(url)\n",
    "        if img:\n",
    "            img.thumbnail((50, 50))\n",
    "            avg_color = np.array(img).mean(axis=(0, 1))\n",
    "            return avg_color\n",
    "    except Exception:\n",
    "        return None\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a199a13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLES_PER_CATEGORY = 20\n",
    "category_avg_colors = []\n",
    "\n",
    "unique_categories = products_cleaned_df[\"merged_category_id\"].unique()\n",
    "\n",
    "print(f\"Sampling {SAMPLES_PER_CATEGORY} images for each of the {len(unique_categories)} categories...\")\n",
    "\n",
    "def process_category_color(category_id):\n",
    "    \"\"\"\n",
    "    Fetches samples for a specific category and calculates the overall mean color.\n",
    "    \"\"\"\n",
    "    cat_df = products_cleaned_df[products_cleaned_df[\"merged_category_id\"] == category_id]\n",
    "    \n",
    "    sample_size = min(SAMPLES_PER_CATEGORY, len(cat_df))\n",
    "    sampled_urls = cat_df.sample(n=sample_size, random_state=42)[\"imgUrl\"].tolist()\n",
    "    \n",
    "    image_colors = []\n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        results = executor.map(get_average_color, sampled_urls)\n",
    "        \n",
    "        for color in results:\n",
    "            if color is not None:\n",
    "                image_colors.append(color)\n",
    "    \n",
    "    if image_colors:\n",
    "        final_color = np.mean(np.array(image_colors), axis=0)\n",
    "        \n",
    "        cat_name_row = mapping_df[mapping_df[\"merged_category_id\"] == category_id]\n",
    "        cat_name = cat_name_row[\"category_name\"].iloc[0] if not cat_name_row.empty else f\"Cat {category_id}\"\n",
    "        \n",
    "        return {\n",
    "            \"category_id\": category_id,\n",
    "            \"category_name\": cat_name,\n",
    "            \"rgb_color\": final_color,\n",
    "            \"normalized_color\": final_color / 255.0  # Normalized\n",
    "        }\n",
    "    return None\n",
    "\n",
    "for cat_id in tqdm(unique_categories, desc=\"Processing Categories\"):\n",
    "    result = process_category_color(cat_id)\n",
    "    if result:\n",
    "        category_avg_colors.append(result)\n",
    "\n",
    "colors_df = pd.DataFrame(category_avg_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368cfb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "if not colors_df.empty:\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    \n",
    "    bars = plt.bar(\n",
    "        colors_df[\"category_name\"], \n",
    "        [1] * len(colors_df), \n",
    "        color=colors_df[\"normalized_color\"],\n",
    "        edgecolor=\"gray\"\n",
    "    )\n",
    "    \n",
    "    plt.xticks(rotation=90)\n",
    "    plt.yticks([])\n",
    "    plt.xlabel(\"Category\")\n",
    "    plt.title(f\"Average Color Profile per Category (n={SAMPLES_PER_CATEGORY})\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No color data extracted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af548bb1",
   "metadata": {},
   "source": [
    "While the images in our dataset consistently feature **pure white backgrounds**, we have elected to retain the images as-is rather than performing/training complex background segmentation or mask generation. Our reasoning is two-fold:\n",
    "\n",
    "1. **High Signal Clarity:** The white background provides a high contrast ratio, allowing the model to easily identify product contours and textures without the initial interference of environmental \"noise.\"\n",
    "2. **Robustness via Augmentation:** To prevent the model from overfitting to this \"studio setting\" (and failing on real-world photos), by applying random brightness shifts, rotations, and color jitters, we simulate real-world variability. This approach is computationally more efficient than segmentation while still forcing the model to learn invariant product features rather than just background-to-object contrast.\n",
    "\n",
    "### Analysis of Average Image Color\n",
    "\n",
    "The visualization below displays the **mean RGB value** for a sample of images within each category. This analysis serves as a validation tool for our dataset:\n",
    "\n",
    "* **Consistency Check:** A very light average color across all categories confirms the dominance of the white background, verifying that our sampling is consistent.\n",
    "* **Inter-Category Variance:** Subtle differences in the average color (e.g., a darker average for \"Books\" vs. a lighter average for \"Electronics\") indicate the typical \"bulk\" or \"density\" of the products within that category.\n",
    "* **Model Bias Awareness:** Since the average color is heavily skewed toward white (RGB ~255, 255, 255), this output reminds us that our normalization layer must be carefully tuned to ensure that the actual product features (the \"minority\" of pixels) are not washed out during training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b79a98",
   "metadata": {},
   "source": [
    "## 8. Training Pipeline\n",
    "To have a high level view and a brief explanation, during training phase, we do the Augmentation process:\n",
    "- **Resize:** To a uniform `224x224` pixels.\n",
    "- **RandomHorizontalFlip:** p=0.5.\n",
    "- **RandomRotation:** 15 degrees.\n",
    "- **ColorJitter:** brightness=0.2, contrast=0.2, saturation=0.2.\n",
    "- **ToTensor:** Convert PIL Image to PyTorch Tensor.\n",
    "- **Normalize:** Use standard ImageNet mean `[0.485, 0.456, 0.406]` and std `[0.229, 0.224, 0.225]`.\n",
    "\n",
    "For validation and testing we do only:\n",
    "- **Resize:** `224x224` pixels.\n",
    "- **ToTensor:** Convert to Tensor.\n",
    "- **Normalize:** Use the same mean and std as the training pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3827c0a2",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we performed a full cycle of data analysis and pipeline validation:\n",
    "- We began by inspecting the **raw dataset** and its original, imbalanced category structure.\n",
    "- We then loaded the results of our **automated NLP-based category merging pipeline**.\n",
    "- We **visualized the final dataset's balance**, confirming that the new 50 categories are much more evenly distributed.\n",
    "- We reviewed the mapping to understand how original categories were grouped.\n",
    "- We verified the quality of image URLs in the dataset.\n",
    "\n",
    "The resulting dataset, `products_cleaned.csv`, is now validated and ready to serve as the foundation for model training."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
